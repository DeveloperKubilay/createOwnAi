from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

print("ğŸ”¥ Model yÃ¼kleniyor...")

# Tokenizer ve model yÃ¼kleme - doÄŸru path
tokenizer = AutoTokenizer.from_pretrained("./trained_model")
model = AutoModelForCausalLM.from_pretrained("./trained_model")

print("âœ… Model yÃ¼klendi!")
print(f"ğŸ§  Model parametreleri: {sum(p.numel() for p in model.parameters())/1e6:.1f}M")

# Test promptlarÄ±
test_prompts = [
    "GPT",
    "Machine learning",
    "Python ile",
    "Training",
    "Neural network"
]

print("\nğŸš€ Model test ediliyor...")

for prompt in test_prompts:
    print(f"\nğŸ“ Prompt: '{prompt}'")
    
    # Tokenize etme
    inputs = tokenizer(prompt, return_tensors="pt")
    
    # Modeli Ã§alÄ±ÅŸtÄ±rma - daha iyi parametreler
    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=15,  # KÄ±sa ama anlamlÄ±
            temperature=0.8,  
            do_sample=True,
            top_p=0.9,  
            repetition_penalty=1.2,  # Tekrar Ã¶nle
            pad_token_id=tokenizer.eos_token_id,
            eos_token_id=tokenizer.eos_token_id
        )
    
    # Ã‡Ä±ktÄ±yÄ± Ã§Ã¶zÃ¼mleme - ULTRA clean decode
    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)
    
    # ByteLevel artifacts temizle
    generated_text = generated_text.replace("Ä ", " ")  # ByteLevel prefix
    generated_text = generated_text.replace("Ã„Â±", "Ä±")  # Turkish i
    generated_text = generated_text.replace("Ã…Å", "ÅŸ")   # Turkish ÅŸ  
    generated_text = generated_text.replace("ÃƒÂ§", "Ã§")   # Turkish Ã§
    generated_text = generated_text.replace("ÃƒÂ¼", "Ã¼")   # Turkish Ã¼
    generated_text = generated_text.replace("ÃƒÂ¶", "Ã¶")   # Turkish Ã¶
    generated_text = generated_text.replace("Ã„Å", "ÄŸ")   # Turkish ÄŸ
    
    # Extra spaces temizle
    import re
    generated_text = re.sub(r'\s+', ' ', generated_text).strip()
    
    # Sadece yeni Ã¼retilen kÄ±smÄ± al (prompt'u Ã§Ä±kar)
    new_text = generated_text[len(prompt):].strip()
    
    print(f"ğŸ¤– Model cevabÄ±: '{prompt}{new_text}'")

print("\nğŸ‰ Bitti!")